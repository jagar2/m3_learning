{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHO Fitter Inferency Noisy Results Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'seaborn'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mh5py\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mseaborn\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39msns\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtime\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'seaborn'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pandas as pd\n",
    "import os\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from scipy.signal import resample\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from src.m3_learning.be.util import print_be_tree\n",
    "from src.m3_learning.be.processing import convert_amp_phase, transform_params, SHO_fit_to_array\n",
    "from src.m3_learning.util.preprocessing import global_scaler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loads data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to open file (unable to open file: name = './data_file.h5', errno = 2, error message = 'No such file or directory', flags = 1, o_flags = 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m path \u001b[39m=\u001b[39m \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m./\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[39m# Opens the data file\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m h5_f \u001b[39m=\u001b[39m h5py\u001b[39m.\u001b[39;49mFile(path \u001b[39m+\u001b[39;49m \u001b[39m\"\u001b[39;49m\u001b[39mdata_file.h5\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mr+\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m \u001b[39m# number of pixels in the image\u001b[39;00m\n\u001b[1;32m      8\u001b[0m num_pix \u001b[39m=\u001b[39m h5_f[\u001b[39m\"\u001b[39m\u001b[39mMeasurement_000\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mattrs[\u001b[39m\"\u001b[39m\u001b[39mnum_pix\u001b[39m\u001b[39m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/envs/rapidfitting/lib/python3.9/site-packages/h5py/_hl/files.py:567\u001b[0m, in \u001b[0;36mFile.__init__\u001b[0;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[1;32m    558\u001b[0m     fapl \u001b[39m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[1;32m    559\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[1;32m    560\u001b[0m                      alignment_threshold\u001b[39m=\u001b[39malignment_threshold,\n\u001b[1;32m    561\u001b[0m                      alignment_interval\u001b[39m=\u001b[39malignment_interval,\n\u001b[1;32m    562\u001b[0m                      meta_block_size\u001b[39m=\u001b[39mmeta_block_size,\n\u001b[1;32m    563\u001b[0m                      \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[1;32m    564\u001b[0m     fcpl \u001b[39m=\u001b[39m make_fcpl(track_order\u001b[39m=\u001b[39mtrack_order, fs_strategy\u001b[39m=\u001b[39mfs_strategy,\n\u001b[1;32m    565\u001b[0m                      fs_persist\u001b[39m=\u001b[39mfs_persist, fs_threshold\u001b[39m=\u001b[39mfs_threshold,\n\u001b[1;32m    566\u001b[0m                      fs_page_size\u001b[39m=\u001b[39mfs_page_size)\n\u001b[0;32m--> 567\u001b[0m     fid \u001b[39m=\u001b[39m make_fid(name, mode, userblock_size, fapl, fcpl, swmr\u001b[39m=\u001b[39;49mswmr)\n\u001b[1;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(libver, \u001b[39mtuple\u001b[39m):\n\u001b[1;32m    570\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_libver \u001b[39m=\u001b[39m libver\n",
      "File \u001b[0;32m~/anaconda3/envs/rapidfitting/lib/python3.9/site-packages/h5py/_hl/files.py:233\u001b[0m, in \u001b[0;36mmake_fid\u001b[0;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[1;32m    231\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mopen(name, flags, fapl\u001b[39m=\u001b[39mfapl)\n\u001b[1;32m    232\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mr+\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 233\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39;49mopen(name, h5f\u001b[39m.\u001b[39;49mACC_RDWR, fapl\u001b[39m=\u001b[39;49mfapl)\n\u001b[1;32m    234\u001b[0m \u001b[39melif\u001b[39;00m mode \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mw-\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m    235\u001b[0m     fid \u001b[39m=\u001b[39m h5f\u001b[39m.\u001b[39mcreate(name, h5f\u001b[39m.\u001b[39mACC_EXCL, fapl\u001b[39m=\u001b[39mfapl, fcpl\u001b[39m=\u001b[39mfcpl)\n",
      "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mh5py/h5f.pyx:106\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to open file (unable to open file: name = './data_file.h5', errno = 2, error message = 'No such file or directory', flags = 1, o_flags = 2)"
     ]
    }
   ],
   "source": [
    "# Sets path to file\n",
    "path = r\"./\"\n",
    "\n",
    "# Opens the data file\n",
    "h5_f = h5py.File(path + \"data_file.h5\", \"r+\")\n",
    "\n",
    "# number of pixels in the image\n",
    "num_pix = h5_f[\"Measurement_000\"].attrs[\"num_pix\"]\n",
    "\n",
    "num_pix_1d = int(np.sqrt(num_pix))\n",
    "\n",
    "# Frequency Vector in Hz\n",
    "frequency_bin = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Bin_Frequencies\"][:]\n",
    "\n",
    "# extracting spectroscopic values\n",
    "spectroscopic_values = h5_f['Measurement_000']['Channel_000']['Spectroscopic_Values']\n",
    "\n",
    "# number of DC voltage steps\n",
    "voltage_steps = h5_f[\"Measurement_000\"].attrs[\"num_udvs_steps\"]\n",
    "\n",
    "# Resampled frequency vector\n",
    "wvec_freq = resample(frequency_bin, 80)\n",
    "\n",
    "# get raw data (real and imaginary combined)\n",
    "raw_data = h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]\n",
    "raw_data_resampled = resample(np.array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data\"]).reshape(-1, 165), 80, axis=1)\n",
    "\n",
    "# conversion of raw data (both resampled and full)\n",
    "amp, phase = convert_amp_phase(raw_data)\n",
    "amp_resample, phase_resample = convert_amp_phase(raw_data_resampled)\n",
    "\n",
    "scaled_data = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['scaled_data'][:]\n",
    "real_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['real_resample'][:]\n",
    "imag_resample = h5_f[\"Measurement_000\"][\"Channel_000\"]['complex']['imag_resample'][:]\n",
    "\n",
    "# scale the real component of input data\n",
    "scaler_real = global_scaler()\n",
    "scaled_data_real = scaler_real.fit_transform(real_resample).reshape(-1, 80)\n",
    "\n",
    "# scale the imaginary component of input data\n",
    "scaler_imag = global_scaler()\n",
    "scaled_data_imag = scaler_imag.fit_transform(imag_resample).reshape(-1, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list for parameters\n",
    "fit_results_list = SHO_fit_to_array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data-SHO_Fit_000\"][\"Fit\"])\n",
    "\n",
    "# flatten parameters list into numpy array\n",
    "fit_results_list = np.array(fit_results_list).reshape(num_pix, voltage_steps, 5)\n",
    "\n",
    "# exclude the R2 parameter\n",
    "params = fit_results_list.reshape(-1, 5)[:, 0:4]\n",
    "\n",
    "# scale the parameters (now takes only 4 parameters, excluding the R2)\n",
    "params_scaler = StandardScaler()\n",
    "scaled_params = params_scaler.fit_transform(fit_results_list.reshape(-1, 5)[:, 0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list for parameters\n",
    "pred_results_list = []\n",
    "for sublist in np.array(\n",
    "    h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data-Predictions_000\"][\"SHO_Pred_Results\"]\n",
    "):\n",
    "    for item in sublist:\n",
    "        for i in item:\n",
    "            pred_results_list.append(i)\n",
    "\n",
    "# flatten parameters list into numpy array\n",
    "pred_results_list = np.array(pred_results_list).reshape(num_pix, voltage_steps, 4)\n",
    "\n",
    "# exclude the R2 parameter\n",
    "all_pred_params = pred_results_list.reshape(-1, 4)\n",
    "\n",
    "all_pred_params_scaled = params_scaler.transform(all_pred_params.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_noise_real = -1.0 * 0.0026878386 # 2.6e-3\n",
    "highest_noise_real = 1.0 * 0.0026878386\n",
    "lowest_noise_imag = -1.0 * 0.0027575183\n",
    "highest_noise_imag = 1.0 * 0.0027575183\n",
    "\n",
    "noise_real = np.random.uniform(lowest_noise_real, highest_noise_real, (3600, 63360))\n",
    "noise_imag = np.random.uniform(lowest_noise_imag, highest_noise_imag, (3600, 63360))\n",
    "noise = noise_real+noise_imag*1.0j\n",
    "\n",
    "noise_levels = ['2.0', '4.0', '7.0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_real_nn = (np.real(noise) - (-6.855169e-06)) / 0.0026878386\n",
    "noise_imag_nn = (np.imag(noise) - (0.00013161483)) / 0.0027575183\n",
    "\n",
    "noise_real_nn = noise_real_nn.reshape(-1, 165)\n",
    "noise_imag_nn = noise_imag_nn.reshape(-1, 165)\n",
    "\n",
    "noise_nn = np.stack((noise_real_nn, noise_imag_nn), axis=2)\n",
    "del noise_real_nn\n",
    "del noise_imag_nn\n",
    "noise_nn_resampled = resample(noise_nn, 80, axis=1)\n",
    "del noise_nn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyTorch Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SHO_Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input block of 1d convolution\n",
    "        self.hidden_x1 = nn.Sequential(\n",
    "            nn.Conv1d(in_channels=2, out_channels=8, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=8, out_channels=6, kernel_size=7),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=6, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # fully connected block\n",
    "        self.hidden_xfc = nn.Sequential(\n",
    "            nn.Linear(256, 20),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(20, 20),\n",
    "            nn.SELU(),\n",
    "        )\n",
    "\n",
    "        # 2nd block of 1d-conv layers\n",
    "        self.hidden_x2 = nn.Sequential(\n",
    "            nn.MaxPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.Conv1d(in_channels=4, out_channels=4, kernel_size=5),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=4, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "            nn.Conv1d(in_channels=2, out_channels=2, kernel_size=3),\n",
    "            nn.SELU(),\n",
    "            nn.AvgPool1d(kernel_size=2),\n",
    "        )\n",
    "\n",
    "        # Flatten layer\n",
    "        self.flatten_layer = nn.Flatten()\n",
    "        \n",
    "        # Final embedding block - Output 4 values - linear\n",
    "        self.hidden_embedding = nn.Sequential(\n",
    "            nn.Linear(26, 16),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(16, 8),\n",
    "            nn.SELU(),\n",
    "            nn.Linear(8, 4),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, n=-1):\n",
    "      x = torch.swapaxes(x, 1, 2) # output shape - samples, (real, imag), frequency\n",
    "      x = self.hidden_x1(x)\n",
    "      xfc = torch.reshape(x, (n, 256)) # batch size, features\n",
    "      xfc = self.hidden_xfc(xfc)\n",
    "      x = torch.reshape(x, (n, 2, 128)) # batch size, (real, imag), timesteps\n",
    "      x = self.hidden_x2(x)\n",
    "      cnn_flat = self.flatten_layer(x)\n",
    "      encoded = torch.cat((cnn_flat, xfc), 1) # merge dense and 1d conv.\n",
    "      embedding = self.hidden_embedding(encoded) # output is 4 parameters\n",
    "\n",
    "      # corrects the scaling of the parameters\n",
    "      unscaled_param = embedding*torch.tensor(params_scaler.var_[0:4]**0.5).cuda() + torch.tensor(params_scaler.mean_[0:4]).cuda()\n",
    "      return unscaled_param"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performs inference and plots results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial fit\n",
    "fit_results_list_init = fit_results_list[:, :, 4]\n",
    "\n",
    "# dummy initialization\n",
    "initial_maps = np.zeros(1000)\n",
    "lsqf_maps_2 = np.zeros(1000)\n",
    "lsqf_maps_4 = np.zeros(1000)\n",
    "lsqf_maps_7 = np.zeros(1000)\n",
    "nn_maps_2 = np.zeros(1000)\n",
    "nn_maps_4 = np.zeros(1000)\n",
    "nn_maps_7 = np.zeros(1000)\n",
    "all_params_transformed = np.zeros(1000)\n",
    "\n",
    "initial_params = np.zeros(1000)\n",
    "lsqf_params_2 = np.zeros(1000)\n",
    "nn_params_2 = np.zeros(1000)\n",
    "lsqf_params_4 = np.zeros(1000)\n",
    "nn_params_4 = np.zeros(1000)\n",
    "lsqf_params_7 = np.zeros(1000)\n",
    "nn_params_7 = np.zeros(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h5_f_fit_noise.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_be_tree(r\"C:\\Users\\Joshua Agar\\Documents\\codes\\m3_learning\\m3_learning\\papers\\2023_Rapid_Fitting\\data_file_noise_7.0.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "h5_f.filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results_list_noise == fit_results_list_noise_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fit_results_list_noise = SHO_fit_to_array(h5_f[\"Measurement_000\"][\"Channel_000\"][\"Raw_Data-SHO_Fit_000\"][\"Fit\"])\n",
    "\n",
    "# flatten parameters list into numpy array\n",
    "fit_results_list_noise = np.array(fit_results_list_noise).reshape(num_pix,voltage_steps,5).copy()\n",
    "fit_results_list_noise = fit_results_list_noise[:, :, :4]\n",
    "\n",
    "\n",
    "plt.hist(fit_results_list_noise[:, :, 0].flatten(), bins=100)\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "fit_results_list_noise_2 = SHO_fit_to_array(h5_f_fit_noise[\"/Raw_Data-SHO_Fit_000/Fit\"])\n",
    "\n",
    "# flatten parameters list into numpy array\n",
    "fit_results_list_noise_2 = np.array(fit_results_list_noise_2).reshape(num_pix,voltage_steps,5).copy()\n",
    "fit_results_list_noise_2 = fit_results_list_noise_2[:, :, :4]\n",
    "\n",
    "plt.hist(fit_results_list_noise_2[:, :, 0].flatten(), bins=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# noisy fits\n",
    "for nl in noise_levels:\n",
    "  h5_f_fit_noise = h5py.File(f'./data_file_noise_{nl}.h5', 'r+')\n",
    "  \n",
    "  # create a list for parameters\n",
    "  fit_results_list_noise = SHO_fit_to_array(h5_f_fit_noise[\"/Raw_Data-SHO_Fit_000/Fit\"])\n",
    "\n",
    "  gc.collect()\n",
    "  \n",
    "  # flatten parameters list into numpy array\n",
    "  fit_results_list_noise = np.array(fit_results_list_noise).reshape(num_pix,voltage_steps,5)\n",
    "  fit_results_list_noise = fit_results_list_noise[:, :, :4]\n",
    "\n",
    "  fit_results_list_transformed_noise, _ = transform_params(fit_results_list_noise.reshape(-1, 4), fit_results_list_noise.reshape(-1, 4))\n",
    "\n",
    "  del fit_results_list_noise\n",
    "  gc.collect()\n",
    "  \n",
    "  noise_level_float = float(nl)\n",
    "  \n",
    "  data_noise_nn = scaled_data + noise_nn_resampled * noise_level_float\n",
    "\n",
    "  # LOADING PARAMS MODEL\n",
    "  batch_size = 128\n",
    "  torch.cuda.empty_cache()\n",
    "  model_parameters = SHO_Model().cuda()\n",
    "  model_parameters.load_state_dict(torch.load(f'./Trained Models/SHO Fitter/model_noise_{nl}_bs128.pt'))\n",
    "\n",
    "  # prediction of parameters\n",
    "  batch_size = 10000\n",
    "  train_dataloader = DataLoader(data_noise_nn, batch_size=batch_size)\n",
    "\n",
    "  num_elements = len(train_dataloader.dataset)\n",
    "  num_batches = len(train_dataloader)\n",
    "  all_pred_params = torch.zeros_like(torch.tensor(params))\n",
    "\n",
    "  for i, train_batch in enumerate(train_dataloader):\n",
    "      start = i*batch_size\n",
    "      end = start + batch_size\n",
    "\n",
    "      if i == num_batches - 1:\n",
    "          end = num_elements\n",
    "\n",
    "      pred_batch = model_parameters(train_batch.float().cuda())\n",
    "      all_pred_params[start:end] = pred_batch.cpu().detach()\n",
    "\n",
    "      del pred_batch\n",
    "      del train_batch\n",
    "      torch.cuda.empty_cache()\n",
    "\n",
    "  gc.collect()\n",
    "  \n",
    "  all_pred_params = all_pred_params.cpu().detach().numpy()\n",
    "\n",
    "  params_copy = np.copy(params)\n",
    "  all_pred_params_copy = np.copy(all_pred_params)\n",
    "\n",
    "  all_params_transformed_noise, all_pred_params_transformed_noise = transform_params(params_copy, all_pred_params_copy)\n",
    "\n",
    "  all_pred_params_scaled_noise = params_scaler.transform(all_pred_params_transformed_noise)\n",
    "  all_params_scaled_noise = params_scaler.transform(all_params_transformed_noise)\n",
    "\n",
    "  if nl == '7.0':\n",
    "    all_pred_params_transformed_noise[:, 3] = all_pred_params_transformed_noise[:, 3] * -1\n",
    "    global initial_maps\n",
    "    global lsqf_maps_7\n",
    "    global nn_maps_7\n",
    "    global all_params_transformed\n",
    "    all_params_transformed = all_params_transformed_noise.copy()\n",
    "    initial_maps = all_params_transformed_noise[:, :].reshape(num_pix, voltage_steps, -1)[:, ::2][:, voltage_steps//4-1:]\n",
    "    lsqf_maps_7 = fit_results_list_transformed_noise[:, :].reshape(num_pix, voltage_steps, -1)[:, ::2][:, voltage_steps//4-1:]\n",
    "    nn_maps_7 = all_pred_params_transformed_noise[:, :].reshape(num_pix, voltage_steps, -1)[:, ::2][:, voltage_steps//4-1:]\n",
    "\n",
    "    global initial_params\n",
    "    initial_params = all_params_transformed_noise.copy()\n",
    "    global lsqf_params_7\n",
    "    lsqf_params_7 = fit_results_list_transformed_noise.copy()\n",
    "    global nn_params_7\n",
    "    nn_params_7 = all_pred_params_transformed_noise.copy()\n",
    "  elif nl == '4.0':\n",
    "    global lsqf_maps_4\n",
    "    global nn_maps_4\n",
    "    lsqf_maps_4 = fit_results_list_transformed_noise[:, :].reshape(num_pix, voltage_steps, -1)[:, ::2][:, voltage_steps//4-1:]\n",
    "    nn_maps_4 = all_pred_params_transformed_noise[:, :].reshape(num_pix, voltage_steps, -1)[:, ::2][:, voltage_steps//4-1:]\n",
    "\n",
    "    global lsqf_params_4\n",
    "    lsqf_params_4 = fit_results_list_transformed_noise.copy()\n",
    "    global nn_params_4\n",
    "    nn_params_4 = all_pred_params_transformed_noise.copy()\n",
    "  elif nl == '2.0':\n",
    "    global lsqf_maps_2\n",
    "    global nn_maps_2\n",
    "    lsqf_maps_2 = fit_results_list_transformed_noise[:, :].reshape(num_pix, voltage_steps, -1)[:, ::2][:, voltage_steps//4-1:]\n",
    "    nn_maps_2 = all_pred_params_transformed_noise[:, :].reshape(num_pix, voltage_steps, -1)[:, ::2][:, voltage_steps//4-1:]\n",
    "\n",
    "    global lsqf_params_2\n",
    "    lsqf_params_2 = fit_results_list_transformed_noise.copy()\n",
    "    global nn_params_2\n",
    "    nn_params_2 = all_pred_params_transformed_noise.copy()\n",
    "  \n",
    "  # plot distributions\n",
    "  fig, axs = plt.subplots(nrows=4, ncols=3, figsize=(20, 26))\n",
    "\n",
    "  units = ['Amplitude (Arb. U.)', 'Frequency (Hz)', 'Quality Factor (Arb. U.)', 'Phase (rad)']\n",
    "\n",
    "  for i in range(4):\n",
    "    axs[i, 0].hist(fit_results_list_transformed_noise[:,i].flatten(), 100)\n",
    "    axs[i, 1].hist(all_pred_params_transformed_noise[:,i].flatten(), 100)\n",
    "    axs[i, 2].hist(all_params_transformed_noise[:,i].flatten(), 100)\n",
    "\n",
    "  i = 0\n",
    "  for ax in axs.flat:\n",
    "      ax.set(xlabel=units[i//3], ylabel='Density')\n",
    "      i+=1\n",
    "      ax.ticklabel_format(axis=\"x\", style=\"sci\", scilimits=(0,0))\n",
    "\n",
    "  axs[0, 0].set_title(f\"Noise {nl} LSQF\", fontsize=15);\n",
    "  axs[0, 1].set_title(f\"Noise {nl} NN\", fontsize=15);\n",
    "  axs[0, 2].set_title(\"Without noise\", fontsize=15);\n",
    "\n",
    "  x_min = [-0.1e-3, 1.24e6, -6e2, -3.5]\n",
    "  x_max = [0.3e-3, 1.36e6, 4e2, 3.5]\n",
    "  y_max = [1.5e6, 1.4e6, 1.4e6, 0.3e6]\n",
    "\n",
    "  for j in range(4):\n",
    "      axs[j, 0].set_xlim(x_min[j], x_max[j])\n",
    "      axs[j, 1].set_xlim(x_min[j], x_max[j])\n",
    "      axs[j, 2].set_xlim(x_min[j], x_max[j])\n",
    "      axs[j, 0].set_ylim(0, y_max[j])\n",
    "      axs[j, 1].set_ylim(0, y_max[j])\n",
    "      axs[j, 2].set_ylim(0, y_max[j])\n",
    "      \n",
    "  plt.savefig(f'Assets/Figures/comparison_noise_{nl}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "amp_min = min(all_params_transformed[:, 0])\n",
    "amp_max = max(all_params_transformed[:, 0])\n",
    "res_min = min(all_params_transformed[:, 1])\n",
    "res_max = max(all_params_transformed[:, 1])\n",
    "qf_min = min(all_params_transformed[:, 2])\n",
    "qf_max = max(all_params_transformed[:, 2])\n",
    "ph_min = min(all_params_transformed[:, 3])\n",
    "ph_max = max(all_params_transformed[:, 3])\n",
    "\n",
    "mins = [amp_min, res_min, qf_min, ph_min]\n",
    "maxs = [amp_max, res_max, qf_max, ph_max]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizes results in the map form for waveform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.reset_orig()\n",
    "plt.rcParams['image.cmap'] = 'magma'\n",
    "plt.rcParams['axes.labelsize'] = 16\n",
    "plt.rcParams['xtick.labelsize'] = 14\n",
    "plt.rcParams['ytick.labelsize'] = 14\n",
    "plt.rcParams['figure.titlesize'] = 20\n",
    "plt.rcParams['xtick.direction'] = 'in'\n",
    "plt.rcParams['ytick.direction'] = 'in'\n",
    "plt.rcParams['xtick.top'] = True\n",
    "plt.rcParams['ytick.right'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "units = ['Amplitude (Arb. U.)', 'Frequency (Hz)', 'Quality Factor\\n(Arb. U.)', 'Phase (rad)']\n",
    "fontsize=14\n",
    "\n",
    "fig, axs = plt.subplots(14, 12, figsize=(30, 30))\n",
    "axes = axs.reshape(-1)\n",
    "for i in range(axes.shape[0]):\n",
    "    if (i >= 92 and i < 96) or (i >= 104 and i < 108) or (i >= 116 and i < 120) or (i >= 128 and i < 132) or (i >= 140 and i < 144) or (i >= 152 and i < 156) or (i >= 164 and i < 168):\n",
    "        fig.delaxes(axes[i])\n",
    "        \n",
    "for voltage_step in range(0, initial_maps.shape[0], 12):\n",
    "    if(voltage_step>48):\n",
    "        break\n",
    "    \n",
    "    x, y = 0, 0\n",
    "    if voltage_step == 0:\n",
    "        x, y = 0, 0\n",
    "    elif voltage_step == 12:\n",
    "        x, y = 0, 4\n",
    "    elif voltage_step == 24:\n",
    "        x, y = 0, 8\n",
    "    elif voltage_step == 36:\n",
    "        x, y = 7, 0\n",
    "    elif voltage_step == 48:\n",
    "        x, y = 7, 4\n",
    "    \n",
    "    for param in range(4):\n",
    "        if (x == 0) and (y == 0 or y == 4 or y == 8):\n",
    "            axs[x, y+param].text(-1, -8, units[param], rotation='horizontal', fontsize=fontsize)\n",
    "        if param == 0 and y == 0:\n",
    "            axs[x, y].set_title(\"LSQF No Noise\", rotation='vertical', x=-0.1, y=0.0, fontsize=fontsize)\n",
    "            axs[x+1, y].set_title(\"LSQF Noise 2.0\", rotation='vertical', x=-0.1, y=0.0, fontsize=fontsize)\n",
    "            axs[x+2, y].set_title(\"LSQF Noise 4.0\", rotation='vertical', x=-0.1, y=0.0, fontsize=fontsize)\n",
    "            axs[x+3, y].set_title(\"LSQF Noise 7.0\", rotation='vertical', x=-0.1, y=0.0, fontsize=fontsize)\n",
    "            axs[x+4, y].set_title(\"NN Noise 2.0\", rotation='vertical', x=-0.1, y=0.0, fontsize=fontsize)\n",
    "            axs[x+5, y].set_title(\"NN Noise 4.0\", rotation='vertical', x=-0.1, y=0.0, fontsize=fontsize)\n",
    "            axs[x+6, y].set_title(\"NN Noise 7.0\", rotation='vertical', x=-0.1, y=0.0, fontsize=fontsize)\n",
    "            \n",
    "        im1 = axs[x, y+param].imshow(initial_maps[:, voltage_step, param].reshape(num_pix_1d,num_pix_1d), vmin=mins[param], vmax=maxs[param])\n",
    "        plt.colorbar(im1, ax=axs[x, y+param], format='%.0e')\n",
    "        im2 = axs[x+1, y+param].imshow(lsqf_maps_2[:, voltage_step, param].reshape(num_pix_1d,num_pix_1d), vmin=mins[param], vmax=maxs[param])\n",
    "        plt.colorbar(im2, ax=axs[x+1, y+param], format='%.0e')\n",
    "        im3 = axs[x+2, y+param].imshow(lsqf_maps_4[:, voltage_step, param].reshape(num_pix_1d,num_pix_1d), vmin=mins[param], vmax=maxs[param])\n",
    "        plt.colorbar(im3, ax=axs[x+2, y+param], format='%.0e')\n",
    "        im4 = axs[x+3, y+param].imshow(lsqf_maps_7[:, voltage_step, param].reshape(num_pix_1d,num_pix_1d), vmin=mins[param], vmax=maxs[param])\n",
    "        plt.colorbar(im4, ax=axs[x+3, y+param], format='%.0e')\n",
    "        im5 = axs[x+4, y+param].imshow(nn_maps_2[:, voltage_step, param].reshape(num_pix_1d,num_pix_1d), vmin=mins[param], vmax=maxs[param])\n",
    "        plt.colorbar(im5, ax=axs[x+4, y+param], format='%.0e')\n",
    "        im6 = axs[x+5, y+param].imshow(nn_maps_4[:, voltage_step, param].reshape(num_pix_1d,num_pix_1d), vmin=mins[param], vmax=maxs[param])\n",
    "        plt.colorbar(im6, ax=axs[x+5, y+param], format='%.0e')\n",
    "        im7 = axs[x+6, y+param].imshow(nn_maps_7[:, voltage_step, param].reshape(num_pix_1d,num_pix_1d), vmin=mins[param], vmax=maxs[param])\n",
    "        plt.colorbar(im7, ax=axs[x+6, y+param], format='%.0e')\n",
    "        \n",
    "axs[0, 1].text(72, -8, '●', rotation='horizontal', fontsize=30)\n",
    "axs[0, 5].text(72, -8, '▼', rotation='horizontal', fontsize=30)\n",
    "axs[0, 9].text(72, -8, '▲', rotation='horizontal', fontsize=30)\n",
    "axs[7, 1].text(72, -4, '▶', rotation='horizontal', fontsize=30)\n",
    "axs[7, 5].text(72, -4, '◀', rotation='horizontal', fontsize=30)\n",
    "        \n",
    "for i in range(axes.shape[0]):\n",
    "    axes[i].axis('off')\n",
    "  \n",
    "plt.tight_layout()\n",
    "plt.savefig('Assets/Figures/loss_comparison_maps.svg')\n",
    "plt.savefig('Assets/Figures/loss_comparison_maps.png')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize distribution of parameters using violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_params_transformed, all_pred_params_transformed = transform_params(params.copy(), all_pred_params.copy())\n",
    "\n",
    "initial_params = (initial_params - params_scaler.mean_) / (params_scaler.var_ ** 0.5)\n",
    "all_pred_params_transformed = (all_pred_params_transformed - params_scaler.mean_) / (params_scaler.var_ ** 0.5)\n",
    "lsqf_params_2 = (lsqf_params_2 - params_scaler.mean_) / (params_scaler.var_ ** 0.5)\n",
    "nn_params_2 = (nn_params_2 - params_scaler.mean_) / (params_scaler.var_ ** 0.5)\n",
    "lsqf_params_4 = (lsqf_params_4 - params_scaler.mean_) / (params_scaler.var_ ** 0.5)\n",
    "nn_params_4 = (nn_params_4 - params_scaler.mean_) / (params_scaler.var_ ** 0.5)\n",
    "lsqf_params_7 = (lsqf_params_7 - params_scaler.mean_) / (params_scaler.var_ ** 0.5)\n",
    "nn_params_7 = (nn_params_7 - params_scaler.mean_) / (params_scaler.var_ ** 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_plot_comp = pd.DataFrame(np.vstack((all_pred_params_transformed, nn_params_2, nn_params_7, initial_params, lsqf_params_2, lsqf_params_7)))\n",
    "df_to_plot_comp = df_to_plot_comp.melt(var_name='Params', value_name='Normalized Params')\n",
    "df_to_plot_comp['Fit Type'] = 'NN'\n",
    "df_to_plot_comp['Noise'] = '0.0'\n",
    "\n",
    "for i in range(1,25,6):\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Fit Type'] = 'NN'\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Noise'] = '2.0'\n",
    "\n",
    "for i in range(2,25,6):\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Fit Type'] = 'NN'\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Noise'] = '7.0'\n",
    "\n",
    "for i in range(3,25,6):\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Fit Type'] = 'LSQF'\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Noise'] = '0.0'\n",
    "\n",
    "for i in range(4,25,6):\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Fit Type'] = 'LSQF'\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Noise'] = '2.0'\n",
    "\n",
    "for i in range(5,25,6):\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Fit Type'] = 'LSQF'\n",
    "  df_to_plot_comp.loc[i*initial_params.shape[0]:(i+1)*initial_params.shape[0], 'Noise'] = '7.0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Amplitude', 'Resonance', 'Q-Factor', 'Phase']\n",
    "\n",
    "sns.set_style(\"ticks\")\n",
    "sns.catplot(x='Params', y='Normalized Params', hue='Fit Type', col='Noise', data=df_to_plot_comp, kind='violin', scale='count', split=True, inner='quartile')\n",
    "\n",
    "plt.tight_layout()\n",
    "sns.despine(fig=None, ax=None, top=False, right=False, left=False, bottom=False, offset=None, trim=False)\n",
    "plt.savefig('Assets/Figures/violin_SHO_params_comparison_noise.png', bbox_inches='tight', pad_inches=1)\n",
    "plt.savefig('Assets/Figures/violin_SHO_params_comparison_noise.svg', bbox_inches='tight', pad_inches=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rapid_fitting",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c58f42fd11d8ae4df132d3c425059695e86ccc63a852aa66615442730ca8b1fc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
